{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import uuid\n",
    "import time\n",
    "import json\n",
    "import copy\n",
    "\n",
    "from models import Models\n",
    "#from tools.utils import *\n",
    "from config import Config\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn import svm\n",
    "from dataset import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"books\"\n",
    "encoding='utf-8'\n",
    "test_set, _ = load_data(os.path.join('dataset', 'raw', name, name+'.task.test'), encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=link_words(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_words(samples):\n",
    "    '''link sentence back\n",
    "    return x, y\n",
    "    '''\n",
    "    x, y = list(), list()\n",
    "    # line: (sentence, label)\n",
    "    for line in samples:\n",
    "        x.append(' '.join(line[0]))\n",
    "        y.append(line[1])\n",
    "    vectorizer = CountVectorizer(ngram_range=(1,3))\n",
    "    x = vectorizer.fit_transform(x).toarray()\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37067"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7912"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44979"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52022"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97001"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro_bow(name, filename, ngram, encoding='utf-8'):\n",
    "    print('Process {} dataset...'.format(name))\n",
    "    word_count = {}\n",
    "    def link_words(samples):\n",
    "        '''link sentence back\n",
    "        return x, y\n",
    "        '''\n",
    "        x, y = list(), list()\n",
    "        # line: (sentence, label)\n",
    "        for line in samples:\n",
    "            sentence = line[0]\n",
    "            for w in sentence:\n",
    "                if w in word_count:\n",
    "                    word_count[w]+=1\n",
    "                else:\n",
    "                    word_count[w]=0\n",
    "        for line in samples:\n",
    "            sentence = []\n",
    "            for w in line[0]:\n",
    "                if word_count[w] >= 20:\n",
    "                    sentence.append(w)\n",
    "            x.append(' '.join(sentence))\n",
    "            y.append(line[1])\n",
    "        vectorizer = CountVectorizer(ngram_range=(1,ngram))\n",
    "        x = vectorizer.fit_transform(x).toarray()\n",
    "        return x, y\n",
    "\n",
    "    # load dataset\n",
    "    train_set, _ = load_data(os.path.join('dataset', 'raw', name, filename+'_train.txt'), encoding=encoding)\n",
    "    #dev_set, _ = load_data(os.path.join('dataset', 'raw', 'books', 'books.task.dev'))\n",
    "    test_set, _ = load_data(os.path.join('dataset', 'raw', name, filename+'_test.txt'), encoding=encoding)\n",
    "    #train_set.extend(dev_set)\n",
    "    train_len = len(train_set)\n",
    "    train_set.extend(test_set)\n",
    "    x_train, y_train = link_words(train_set)\n",
    "    x_test, y_test = x_train[train_len:], y_train[train_len:]\n",
    "    x_train, y_train = x_train[:train_len], y_train[:train_len]\n",
    "    print('Process {} dataset done'.format(name))\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "def single_task(task, model_name, ngram=1):\n",
    "    def score(y_pred, y):\n",
    "        assert len(y_pred) == len(y), 'y_pred and y have different lenght'\n",
    "        acc = 0\n",
    "        for y1, y2 in zip(y_pred, y):\n",
    "            if y1 == y2:\n",
    "                acc += 1\n",
    "        return float(acc) / len(y)\n",
    "    if model_name == 'Bayes':\n",
    "        clf = MultinomialNB()\n",
    "    elif model_name == 'svm':\n",
    "        clf = svm.SVC(gamma='scale')\n",
    "\n",
    "    x_train, y_train, x_test, y_test = prepro_bow(task, task,ngram)\n",
    "\n",
    "    clf.fit(x_train, y_train)\n",
    "    #print('fit done')\n",
    "    \n",
    "    print(cross_val_score(clf, x_train, y_train, scoring='accuracy', cv=10))\n",
    "\n",
    "    #print('Accuracy: {}'.format(score(clf.predict(x_test), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process imdb dataset...\n",
      "Process imdb dataset done\n",
      "[0.8488 0.844  0.8364 0.8312 0.8404 0.8464 0.844  0.858  0.8428 0.842 ]\n"
     ]
    }
   ],
   "source": [
    "single_task('imdb', 'Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process imdb dataset...\n",
      "Process imdb dataset done\n"
     ]
    }
   ],
   "source": [
    "single_task('imdb', 'Bayes', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_task('imdb', 'Bayes', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process books dataset...\n",
      "[0.71428571 0.86956522 0.80625    0.725      0.8375     0.7625\n",
      " 0.8        0.74375    0.79245283 0.77358491]\n"
     ]
    }
   ],
   "source": [
    "single_task('books', 'Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process books dataset...\n",
      "[0.71428571 0.8136646  0.80625    0.73125    0.8125     0.8\n",
      " 0.7625     0.80625    0.79874214 0.81132075]\n"
     ]
    }
   ],
   "source": [
    "single_task('books', 'Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process books dataset...\n",
      "[0.74534161 0.86335404 0.8125     0.75       0.86875    0.80625\n",
      " 0.78125    0.7625     0.81132075 0.79245283]\n"
     ]
    }
   ],
   "source": [
    "single_task('books', 'Bayes')#1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process books dataset...\n",
      "[0.72049689 0.74534161 0.71875    0.73125    0.75       0.7125\n",
      " 0.7125     0.7        0.67924528 0.77987421]\n"
     ]
    }
   ],
   "source": [
    "single_task('books', 'Bayes')#3,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process books dataset...\n",
      "[0.76397516 0.86956522 0.8375     0.76875    0.85625    0.8\n",
      " 0.80625    0.7875     0.82389937 0.79245283]\n"
     ]
    }
   ],
   "source": [
    "single_task('books', 'Bayes')#1,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process books dataset...\n",
      "[0.76397516 0.88198758 0.8375     0.7875     0.8375     0.8125\n",
      " 0.8125     0.8125     0.79245283 0.81132075]\n"
     ]
    }
   ],
   "source": [
    "single_task('books', 'Bayes')#1,4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getall(name, encoding='utf-8'):\n",
    "    filename = name\n",
    "    train_set, _ = load_data(os.path.join('dataset', 'raw', name, filename+'.task.train'), encoding=encoding)\n",
    "    #dev_set, _ = load_data(os.path.join('dataset', 'raw', name, filename+'.task.dev'), encoding=encoding)\n",
    "    test_set, _ = load_data(os.path.join('dataset', 'raw', name, filename+'.task.test'), encoding=encoding)\n",
    "    #train_set.extend(dev_set)\n",
    "    train_set.extend(test_set)\n",
    "    train_len = len(train_set)\n",
    "    return train_set, train_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = getall('kitchen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict()\n",
    "for i, j in a:\n",
    "    if j not in d:\n",
    "        d[j]=1\n",
    "    else:\n",
    "        d[j]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1000, 0: 1000}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_meta_data = {\n",
    "    'books': [1000, 1000],\n",
    "    'electronics': [1000, 1000],\n",
    "    'kitchen': [1000, 1000],\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-base",
   "language": "python",
   "name": "conda-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
